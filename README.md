<div align="center">
  <h1>ðŸŽ¨ MultiModalHugs</h1>
</div>

**MultimodalHugs** is a streamlined extension of [Hugging Face](https://huggingface.co/) designed for training, evaluating, and deploying multimodal AI models. Built atop Hugging Faceâ€™s powerful ecosystem, MultimodalHugs integrates seamlessly with standard pipelines while providing additional functionalities to handle multilingual and multimodal inputsâ€”reducing boilerplate and simplifying your codebase.

---

## Key Features

- **Unified Framework**: Train and evaluate multimodal models (e.g., image-to-text, pose-to-text, signwriting-to-text) using a consistent API.
- **Minimal Code Changes**: Leverage Hugging Faceâ€™s pipelines with only minor modifications.
- **Data in TSV**: Avoid the complexity of numerous hyperparameters by maintaining data splits in `.tsv` filesâ€”easily specify prompts, languages, targets, or other attributes in dedicated columns.
- **Modular Design**: Use or extend any of the components (datasets, models, modules, processors) to suit your custom tasks.
- **Examples Included**: Refer to the `examples/` directory for guided scripts, configurations, and best practices.

---

## Installation

1. **Clone the repository**:

   ```bash
   git clone https://github.com/GerrySant/multimodalhugs.git
   ```

2. **Navigate and install the package**:

   - **Standard installation**:
      ```bash
       cd multimodalhugs
       pip install .
      ```
   - **Developer installation**:
      ```bash
       cd multimodalhugs
       pip install -e .[dev]
      ```
## Usage
Explore the [examples/multimodal_translation/](/examples/multimodal_translation/) directory for an end-to-end workflow demonstrating how to:

1. **Preprocess Data**: Convert raw data into `.tsv` format with columns for prompts, languages, target labels, etc.
2. **Configure Training**: Tune model hyperparameters via YAML or Python script.
3. **Train & Evaluate**: Utilize the included training scripts and Hugging Face's Trainer for effortless experimentation.
4. **Extend & Adapt**: Incorporate custom datasets, tokenizers, or specialized processing modules.

>**Note**: Each example folder (e.g., Image2text_translation, pose2text_translation) contains its own detailed documentation. Refer there for more specifics.

## Directory Overview
```kotlin
multimodalhugs/
â”œâ”€â”€ README.md               # Project overview
â”œâ”€â”€ LICENSE                 # License information
â”œâ”€â”€ pyproject.toml          # Package dependencies and setup
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ data/               # Data-related documentation
â”‚   â””â”€â”€ models/             # Model-related documentation
â”œâ”€â”€ examples/               # Example scripts and configurations
â”‚   â”œâ”€â”€ multimodal_translation/
â”‚   â”‚   â”œâ”€â”€ image2text_translation/
â”‚   â”‚   â”œâ”€â”€ pose2text_translation/
â”‚   â”‚   â””â”€â”€ signwriting2text_translation/
â”œâ”€â”€ multimodalhugs/         # Core framework
â”‚   â”œâ”€â”€ data/               # Data handling utilities
â”‚   â”œâ”€â”€ models/             # Model implementations
â”‚   â”œâ”€â”€ modules/            # Custom components (adapters, embeddings, etc.)
â”‚   â”œâ”€â”€ processors/         # Preprocessing modules
â”‚   â”œâ”€â”€ tasks/              # Task-specific logic (e.g., translation)
â”‚   â”œâ”€â”€ training_setup/     # Training pipeline setup
â”‚   â”œâ”€â”€ multimodalhugs_cli/ # Command-line interface for training/inference
â”‚   â””â”€â”€ utils/              # Helper functions
â”œâ”€â”€ scripts/                # Utility scripts (e.g., documentation generation)
â”œâ”€â”€ tests/                  # Unit tests
â””â”€â”€ .github/                # GitHub actions and workflows

```

- `docs/`: Documentation files for data configurations, datasets, and models.
- `examples/`: Contains ready-to-run demos for various multimodal tasks.
- `multimodalhugs/`: Core library code (datasets, models, modules, etc.).
- `scripts/`: Utility scripts for documentation generation and other automation tasks.
- `tests/`: Automated tests to ensure code integrity.
- `.github/`: GitHub Actions and workflows for CI/CD.

## Contributing
All contributionsâ€”bug reports, feature requests, or pull requestsâ€”are welcome. Please see our [GitHub repository](https://github.com/GerrySant/multimodalhugs) to get involved.

## License
This project is licensed under the terms of the MIT License.

## Citing this Work
If you use MultimodalHugs in your research or applications, please cite:

```bibtex
@misc{multimodalhugs2024, 
    title={MultimodalHugs: A Reproducibility-Driven Framework for Multimodal Machine Translation},
    author={Sant, Gerard and Moryossef, Amit and Jiang, Zifan and Escolano, Carlos},
    howpublished={\url{https://github.com/GerrySant/multimodalhugs}},
    year={2024}
}
```
