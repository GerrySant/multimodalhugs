# Example: Pose-to-text translation with Phoenix

## Setup

Make sure you have a Python virtual environment with `multimodalhugs` installed. Also install the following library:

```bash
pip install git+https://github.com/sign-language-processing/datasets.git
```

## Run all steps

The script `scripts/run.sh` runs all steps automatically. Before calling this script, modify the variables in the top
section of this script:

`base`: a folder where the data, model, etc. of this experiment will appear

`scripts`: path to the `scripts` folder of this example on your local machine

`dry_run`: prepare and train on only a handful of examples, as a sanity check. Also, training will run on CPU instead of GPU. Set to `true` or `false`.

Then:

```bash
./scripts/run.sh
```

In a nutshell, this will fine-tune a pose-to-text translation model on PHOENIX data, using the [M2M_100 model](https://huggingface.co/docs/transformers/en/model_doc/m2m_100) as a
starting point. Mediapipe Holistic poses are used.

If you are working on a SLURM cluster, see [this repository](https://github.com/bricksdont/multimodalhugs-examples) for even more complete / reproducible code.

## More detailed explanations

All files will be created at a certain location (depending on `base` in `run.sh`). Defining dummy folders just for the
purpose of this walk-through:

```bash
base=/home/mathmu/phoenix_experiment
data=$base/data
configs=$base/configs
models=$base/models
translations=$base/translations

mkdir -p $data $configs $models $translations
```

### 1) Prepare phoenix data

The script `scripts/phoenix_dataset_preprocessing.py` downloads and prepares the PHOENIX dataset. It is called as follows:

```bash
python scripts/phoenix_dataset_preprocessing.py \
    --pose-dir $data/poses \
    --output-dir $data/tsv
```

Required arguments:

`--pose-dir`: output folder for pose files (one `.pose` file for each example in the dataset)

`--output-dir`: output folder for the train, validation and test TSV files with metadata

Optional arguments:

`--tfds-data-dir`: in case you'd like to store tensorflow-datasets data in a custom folder. The [default folder for TFDS
is `~/tensorflow_datasets`](https://www.tensorflow.org/datasets/overview#tfdsload), which is not always convenient.

`--dry-run`: process only a handful of examples, for a sanity check before running on all of the data. For example to 
check if the output paths are correct.

See `scripts/phoenix_dataset_preprocessing.sh` for an actual call to this Python script.

The folder `data` in this repository has some example dummy data to show the expected structure of the TSV files.

### 2) Creating a config

Since some of the config parameters cannot be hard-coded (e.g. local paths), the config is generated by the script 
`scripts/create_config.py`:

```bash
python scripts/create_config.py \
    --run-name "phoenix" \
    --config-dir $configs \
    --train-metadata-file $data/tsv/rwth_phoenix2014_t.train.tsv \
    --validation-metadata-file $data/tsv/rwth_phoenix2014_t.validation.tsv \
    --test-metadata-file $data/tsv/rwth_phoenix2014_t.test.tsv \
    --new-vocabulary "__dgs__" \
    --reduce-holistic-poses
```

The resulting config file will be called `config_phoenix.yaml`.

Required arguments:

`...-metadata-file` parameters: paths that point to the TSV files generated by the preprocessing step above.

`--run-name`: name for the Huggingface model / experiment

`--config-dir`: where the output config file (`config_phoenix.yaml`) should be saved

Optional arguments:

`--new-vocabulary`: new tokens that must be added to the pretrained tokenizer and model

`--reduce-holistic-poses`: reduce the keypoints of the face mesh to just contours

`dry-run`: will result in a training config that trains a model for very few steps only

The folder `configs` in this repository has an example config file for reference (even though the real one is generated
dynamically).

### 3) Setup

```bash
multimodalhugs-setup \
    --modality "pose2text" \
    --config_path $configs/config_phoenix.yaml \
    --output_dir $models
```

The setup files will be stored as a sub-folder of `--output-dir` called `setup`, so in this case
`$models/setup`.

For more information about this step, see the [main documentation](https://github.com/GerrySant/multimodalhugs/blob/master/docs/general/CLI.md#multimodalhugs-setup).

### 4) Training

```bash
multimodalhugs-train \
    --task "translation" \
    --config_path $configs/config_phoenix.yaml \
    --setup_path $models/setup \
    --output_dir $models
```

If you don't have WANDB logging enabled, add the argument `--report_to none`.

For more information about this step, see the [main documentation](https://github.com/GerrySant/multimodalhugs/blob/master/docs/general/CLI.md#multimodalhugs-train).

### 5) Translation and evaluation

```bash
multimodalhugs-generate \
    --task "translation" \
    --config_path $configs/config_phoenix.yaml \
    --metric_name "sacrebleu" \
    --output_dir $translations \
    --setup_path $models/setup
```

This will translate and evaluate the test data, resulting in a final sacreBLEU score.

For more information about this step, see the [main documentation](https://github.com/GerrySant/multimodalhugs/blob/master/docs/general/CLI.md#multimodalhugs-generate).
