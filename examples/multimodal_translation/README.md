# Multimodal Machine Translation

This framework focuses on translating sign language into written language using a multimodal approach. It leverages existing components from the [Hugging Face](https://huggingface.co/) ecosystem to facilitate efficient and robust model training. The multimodal setup includes handling both multimodal and textual inputs for translation tasks.

Here are a few end-to-end experimental examples:

- [SignWriting2Text](/examples/multimodal_translation/signwriting2text_translation/)
- [image2Text](/examples/multimodal_translation/image2text_translation/)
- [Pose2Text](/examples/multimodal_translation/pose2text_translation/)
- Video2Text (Example not created yet)



