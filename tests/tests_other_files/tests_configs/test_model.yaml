model:
  name: small_multimodal_embedder
  feature_extractor_type: clip
  pretrained_feature_extractor:
  vl_mapper_type: linear
  vl_mapper_layer_norm_before: true
  vl_mapper_layer_norm: false
  vl_mapper_activation: false
  vl_factor: 1  # Reduce the vl_factor to decrease complexity
  vl_mapper_dropout: 0.0  # Remove dropout for fast overfitting
  backbone_name: m2m_100
  backbone_cfg:
    vocab_size: 8039
    backbone_argumnets: whatever
    d_model: 32    # Reduce model dimension for smaller model
    encoder_layers: 1    # Fewer layers for simplicity
    encoder_attention_heads: 1
    decoder_layers: 1    # Fewer layers for simplicity
    decoder_attention_heads: 1
    decoder_ffn_dim: 64    # Smaller feed-forward network
    encoder_ffn_dim: 64
  pretrained_backbone:
  encoder_embed_dim: 32  # Smaller embedding dimension
  feat_dim: 32  # Smaller feature dimension
  num_labels: 2
  pad_token_id: 1
  eos_token_id: 2
  bos_token_id: 2
  no_scale_embedding: false
  init_lang_abbr: avg
  freeze_feature_extractor: false
  freeze_vl_mapper: false
  freeze_lang_embeddings: false
  freeze_backbone: false
  feature_extractor_cfg:
    feature_extractor_argumnets: whatever
    projection_dim: 32  # Smaller projection dimension
    vision_config:
      hidden_size: 32    # Reduce hidden size
      num_hidden_layers: 1    # Fewer hidden layers
      num_attention_heads: 1
      intermediate_size: 64    # Smaller intermediate size
      projection_dim: 32    # Reduce projection dimension
      image_size: 32
  new_embeddings_vocab_size: 79
  backbone_used_vocab_size: 8039
data:
  src_lang_tokenizer_path: tests/tests_other_files/new_languages.txt
  text_tokenizer_path: tests/tests_other_files/tiny_tokenizer   # /home/gsantm/store/other/tiny_tokenizer.json #facebook/m2m100_418M
